experiment_name:
seed: 0

environment: minigrid
    
minigrid:
    size: [50, 50]
    living_reward: 0
    no_op_penalty: 0
    starting_position:  [0, 0] # random if not given
    num_rewards: 3
    reward_positions: [[38, 45], [5, 12], [48, 1]] # random if not given
    reward_magnitudes: [1., 1., 2.]
    repeat_rewards: False
    episode_timeout: 400 # infinity if not given

learner: 
    type: sarsa_lambda
    learning_rate: 0.1
    discount_factor: 0.99 
    epsilon: 0.1
    visitation_penalty: 0
    initialisation: random

sarsa_lambda:
    trace_lambda: 0.05
    behaviour: epsilon_greedy
    target: greedy

q_learning:
    behaviour: epsilon_greedy
    target: greedy

training:
    num_episodes: 10000
    test_frequency: 1
    full_test_log_frequency: 2500
    train_log_frequency: 2500

logging:
    checkpoint_frequency: 100
    columns:
        - train_episode_reward
        - train_episode_length
        - test_episode_reward
        - test_episode_length
        - no_repeat_test_episode_reward
        - no_repeat_test_episode_length
    arrays:
    plots:
        - plot_episode_lengths
        - plot_episode_rewards
        - no_repeat_test_episode_length
        - no_repeat_test_episode_reward
        - visitation_count_heatmap
        - individual_test_run
        - individual_train_run
        - individual_no_rep_test_run
        - individual_no_rep_train_run

post_processing:
    plot_tags:
        - train_episode_reward
        - train_episode_length
        - test_episode_reward
        - test_episode_length
        